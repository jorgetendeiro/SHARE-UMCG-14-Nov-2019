---
title:    "Bayesian statistics as a therapy for frequentist problems"
subtitle: "Part 2: Bayes in action"
author:   "Jorge N. Tendeiro"
date:     "November 14, 2019<br><br> [https://github.com/jorgetendeiro/SHARE-UMCG-14-Nov-2019](https://github.com/jorgetendeiro/SHARE-UMCG-14-Nov-2019)"
header-includes:
  - \usepackage{amsmath}
output:   
  bookdown::html_document2:
    toc: true
    toc_float:
      collapsed: false
    toc_depth: 2
    fig_caption: true
    number_sections: true
    theme: cosmo        
    highlight: kate
    df_print: kable
    code_folding: show
  pdf_document:
    toc: yes
bibliography: ../references.bib
csl: ../style/apa-old-doi-prefix.csl
---

<br><br>



# Set up

I will illustrate how to perform Bayesian estimation with a simple example. To make the contrast with the frequentist analysis clearer, I will fit the same model in the classic way too. This way, we can better compare the two paradigms. R will be the statistical software used.

The empirical data are a sample from the classical 'Intensive Care Unit' (ICU) data set [@hosmer2013; @lemeshow1988a]. This sample is freely available from the [vcdExtra](https://cran.r-project.org/web/packages/vcdExtra/index.html) R package [@friendly2017a]. I will be fitting a logistic regression model which tries to predict the survival of adult patients following hospital discharge.

In order to fit Bayesian logistic regression, I decided to use the [rstanarm](https://cran.r-project.org/web/packages/rstanarm/index.html) R package [@gabry2018]. This package offers a front-end to Stan ([https://mc-stan.org](https://mc-stan.org)) and is relatively easy to use.

For the Bayesian analysis below, I drew inspiration from a vignette from Aki Vehtari, Jonah Gabry, and Ben Goodrich ([https://avehtari.github.io/modelselection/diabetes.html](https://avehtari.github.io/modelselection/diabetes.html)).

## Prepare environment

```{r results="hide", message=FALSE}
# Clean up:
rm(list = ls())
graphics.off()

# Load libraries (install if needed):
library(vcdExtra)  # For the ICU data
library(rstanarm)  # To fit Bayesian models
library(ggplot2)   # For plotting
library(pROC)      # ROC curve

# Parallel computing for Stan:
options(mc.cores = parallel::detectCores())
```



# The data

```{r message=FALSE}
# Load data (from the 'vcdExtra' package):
data(ICU)  # 200 cases, 22 variables

# Look at data:
  # DV = 'died' (0 = No, 1 = Yes)
  # See ?ICU for details on each variable.
str(ICU)   
```

# Fit logistic regression model

Inspired by the `vcdExtra' example with these data, I decided to fit the following model for illustratation purposes:

$$
\DeclareMathOperator{\logit}{logit}
\begin{align}
\logit(P(\text{died}=Yes))=\alpha + \beta_1\text{age} + \beta_2\text{cancer} + \beta_3\text{admit} + \beta_4\text{uncons}.
\end{align}
$$

## Frequentist

```{r}
icu.freq <- glm(died   ~ age + cancer  + admit + uncons, 
                data   = ICU, 
                family = binomial)

summary(icu.freq)
```

Plot the estimated probability against the jittered outcome:
```{r message=FALSE}
par(mar = c(4, 6.5, 2, 0))
est.prob <- predict(icu.freq, type = c("response"))
roc.out  <- roc(died ~ est.prob, data = ICU)

died.vec <- as.numeric(ICU$died) - 1 # 0 = No, 1 = Yes
plot(est.prob, jitter(died.vec, .2), 
     pch = 21, bg = "gray", bty = "n", 
     xlab = "", ylab = "", las = 1)
mtext("Estimated probability", 1, 2)
mtext("Jittered DV", 2, 2.5)
```

Plot sensitivity and specificity at all possible probability cutoff points:

```{r message=FALSE}
par(mar = c(4, 6.5, 2, 0))
plot(roc.out$thresholds, roc.out$sensitivities, xlim = c(0, 1), 
     type = "l", lwd = 2, bty = "n", 
     xlab = "", ylab = "", axes = FALSE, 
     main = "")
lines(roc.out$thresholds, roc.out$specificities, 
     type = "l", lwd = 2, lty = 2)
axis(1, pos=0)
mtext("Probability cutoff", 1, 1.5)
axis(2, pos=0, las = 1)
mtext("Sensitivity / Specificity", 2, 1.5)
abline(v = .2, col = 2, lwd = 2)
legend(.7, .8, c("Sensitivity" , "Specificity"), lty = 1:2, lwd = 2, seg.len = 3)
```

So a probability cutoff value of about .2 is the one that optimizes both sensitivity and specificity. For illustration purposes only, we will use this value in what follows.

Here are the histograms of the estimated probabilities by outcome value (died = No, died = Yes):

```{r message=FALSE}
par(mar = c(4, 6.5, 2, 0), xpd = NA)
layout(matrix(c(1, 2), ncol = 1))

cut      <- .1999
onemspec <- mean(est.prob[died.vec == 0] > cut)
sensit   <- mean(est.prob[died.vec == 1] > cut)

h1 <- hist(est.prob[died.vec == 0], plot = FALSE)
cutoff.bins <- cut(h1$breaks, c(-Inf, cut, Inf), right = TRUE)
plot(h1, col = c("gray", "red")[cutoff.bins], 
     las = 1, freq = FALSE, main = "", xlab = "")
title("Died = No", adj = 1)
arrows (cut+.02, 3, .40, 3, length = 0.08, lwd = 2, col = "red")
text(.5, 3, paste0("1 - Specificity = ", onemspec), adj = 0, col = "red")

hist(est.prob[died.vec == 1], freq = FALSE, las = 1, 
     col = c("gray", "red")[cutoff.bins], main = "", xlab = "")
title("Died = Yes", adj = 1)
arrows (cut+.02, 2.2, .40, 2.2, length = 0.08, lwd = 2, col = "red")
text(.5, 2.2, paste0("Sensitivity = ", sensit), adj = 0, col = "red")
mtext("Estimated probability", 1, 2)
segments(cut, par("usr")[1], cut, 7, lwd = 2, col = "red")
```

The two histograms look different enough: There is hope of building a good classifier. 

The ROC curve:

```{r message=FALSE}
# plot(roc.out)   # Not so nice!...

# A pimped-up ROC plot:
plot(1-roc.out$specificities, roc.out$sensitivities, 
     type = "l", lwd = 2, bty = "n", 
     xlab = "", ylab = "", axes = FALSE, 
     main = "AUC = .85")
segments(0, 0, 1, 1, lty = 2, col = "gray")
axis(1, pos=0)
mtext("1 - Specificity", 1, 1.5)
axis(2, pos=0, las = 1)
mtext("Sensitivity", 2, 1.5)
segments(onemspec, 0, onemspec, sensit, col = 2)
segments(0, sensit, onemspec, sensit, col = 2)
points(onemspec, sensit, pch = 21, bg = 2)
```

The AUR is .85, so the predicted probability of non survival after hospital discharge is much larger for the patients who actually did not make it. So the model is working as intended.

## Bayesian

```{r}
icu.bayes <- stan_glm(died   ~ age + cancer  + admit + uncons, 
                      data   = ICU, 
                      family = binomial)

summary(icu.bayes, digits = 3)

# Plot posterior distributions:
plot(icu.bayes, "areas", prob = 0.95, prob_outer = 1) + geom_vline(xintercept = 0)

# Humm, not very clear.
# Plot 'age' separately (its SE is way smaller than the others):
plot(icu.bayes, "areas", prob = 0.95, prob_outer = 1, 
     pars = c("(Intercept)", "cancerYes", "admitEmergency", "unconsYes")) + 
  geom_vline(xintercept = 0)

plot(icu.bayes, "areas", prob = 0.95, prob_outer = 1, 
     pars = c("age")) + 
  geom_vline(xintercept = 0)
```


# Compare results

## Point estimates

```{r echo=FALSE}
df.coef <- round(data.frame(summary(icu.freq)$coef[, c("Estimate", "Std. Error")], 
                      summary(icu.bayes)[1:5, c("mean", "sd")]), 2)
colnames(df.coef) <- c("B freq", "SE freq",  "B bayes", "SE bayes")
df.coef
```

## Interval estimates

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
confint           (icu.freq,  level = .95)  # Frequentist 95% **confidence** interval
posterior_interval(icu.bayes, prob  = .95)  # Bayesian 95% **credible** interval
```

```{r echo=FALSE}
freq.CIs  <- confint           (icu.freq,  level = .95)
bayes.CIs <- posterior_interval(icu.bayes, prob  = .95)
df.CIs <- round(data.frame(freq.CIs, bayes.CIs), 2)
colnames(df.CIs) <- c("LB freq", "UB freq",  "LB bayes", "UB bayes")
df.CIs
```

<!-- ## Predicted log-odds  -->

<!-- ```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'} -->
<!-- predict(icu.freq, type = "link") -->
<!-- icu.bayes$linear.predictors -->
<!-- ``` -->

<!-- ```{r echo=FALSE} -->
<!-- # Freq: -->
<!-- tmp             <- predict(icu.freq, type = "link", se.fit = TRUE) -->
<!-- freq.logodds    <- tmp$fit -->
<!-- freq.logodds.se <- tmp$se.fit -->
<!-- rm(tmp) -->
<!-- # Bayes: -->
<!-- # I miss the SEs, so I compute predictions and SEs them from the stan object directly: -->
<!-- icu.bayes.stan    <- as.matrix(icu.bayes$stanfit) -->
<!-- icu.bayes.stan    <- icu.bayes.stan[, 1:5] -->
<!-- icu.bayes.linpred <- icu.bayes.stan %*% t(cbind(1,  -->
<!--                                                 ICU[, "age"],  -->
<!--                                                 as.numeric(ICU[,"cancer"])-1,  -->
<!--                                                 as.numeric(ICU[,"admit"])-1,  -->
<!--                                                 as.numeric(ICU[,"uncons"])-1)) -->
<!-- bayes.logodds    <- colMeans(icu.bayes.linpred) -->
<!-- # bayes.logodds ~ icu.bayes$linear.predictors, differences are due to random drawing from the posteriors. -->
<!-- bayes.logodds.se <- apply(icu.bayes.linpred, 2, sd) -->

<!-- plot(freq.logodds[order(freq.logodds)], type = "l", bty = "n", ylim = c(-6.5, 3.5), las = 1, yaxt = "n") -->
<!-- axis(2, seq(-6, 3, 2), las = 1) -->
<!-- lines(bayes.logodds[order(freq.logodds)] + bayes.logodds.se[order(freq.logodds)], lwd = .5) -->
<!-- lines(bayes.logodds[order(freq.logodds)] - bayes.logodds.se[order(freq.logodds)], lwd = .5) -->


<!-- lines(bayes.logodds[order(freq.logodds)], type = "l", type = 2) -->
<!-- ``` -->


<!-- ## Predicted probabilities -->

<!-- ```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'} -->
<!-- predict(icu.freq, type = "response", se.fit = TRUE) -->
<!-- icu.bayes$fitted.values -->
<!-- ``` -->

## Interim conclusions

The numerical estimates look very close...

So, why should we bother using Bayesian statistics?...



# Posterior predictive distribution

## Classification accuracy

Compare observed $y$ scores (0 = not died; 1 = died) with predicted $y$ scores.

Here we do in-sample prediction (out-of-sample prediction would be ideal).

```{r}
# Predicted probabilities
logodds <- posterior_linpred(icu.bayes)
prob    <- posterior_linpred(icu.bayes, transform = TRUE)
prob    <- colMeans(prob)
pred.died      <- as.integer(prob >= 0.5)
   
# posterior classification accuracy
round(mean(xor(pred.died,as.integer(ICU$died=="No"))),2)
```










`r if (knitr::is_html_output()) '# References {-}'`


